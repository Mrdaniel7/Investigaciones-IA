<!DOCTYPE html><html lang="en-gb"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><title>Crear Lm - Experimetos IA</title><meta name="description" content="üß™ Creando mi propio LLM: De Cero a H√©roe (Gu√≠a Visual) ¬°Hola a todos! Hoy os traigo algo especial. Vamos a desmontar la&hellip;"><meta name="generator" content="Publii Open-Source CMS for Static Site"><link rel="canonical" href="./crear-lm.html"><link rel="stylesheet" href="./assets/css/fontawesome-all.min.css?v=85514f933f9e0b82460af63f1a403fa5"><link rel="stylesheet" href="./assets/css/style.css?v=6d92336350d5374cc2b2fb5720b76be5"><noscript><link rel="stylesheet" href="./assets/css/noscript.css?v=efa867a99f5064d6729e4dc2008ad50b"></noscript><script type="application/ld+json">{"@context":"http://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"./crear-lm.html"},"headline":"Crear Lm","datePublished":"2026-02-14T10:04+01:00","dateModified":"2026-02-14T10:30+01:00","description":"üß™ Creando mi propio LLM: De Cero a H√©roe (Gu√≠a Visual) ¬°Hola a todos! Hoy os traigo algo especial. Vamos a desmontar la&hellip;","author":{"@type":"Person","name":"Daniel Terroba Alcala","url":"./authors/daniel-terroba-alcala/"},"publisher":{"@type":"Organization","name":"Daniel Terroba Alcala"}}</script><style>#wrapper > .bg {
               background-image: url(./assets/images/overlay.png), linear-gradient(0deg, rgba(0, 0, 0, 0.1), rgba(0, 0, 0, 0.1)), url();
           }</style><noscript><style>img[loading] {
                    opacity: 1;
                }</style></noscript></head><body class="is-preload page-template"><div id="wrapper"><header id="header"><a class="logo" href="./">Experimetos IA</a></header><nav id="nav"><ul class="links"><li><a href="./cuantizacion.html" target="_self">Cuantizacion</a></li><li><a href="./agente-opencode.html" target="_self">Agente</a></li><li><a href="./fine-tuning.html" target="_self">Fine Tuning</a></li><li><a href="./preentrenamiento.html" target="_self">Preentrenamiento</a></li><li><a href="./destilacion.html" target="_self">Destilaci√≥n</a></li><li class="active"><a href="./crear-lm.html" target="_self">Crear un Llm</a></li></ul></nav><main id="main"><article class="post"><header class="major"><h1>Crear Lm</h1><p class="post__inner"></p></header><div class="post__inner post__entry"><div id="quant-guide-container"><h1 style="color: #58a6ff; font-size: 2em; margin-bottom: 10px;">üß™ Creando mi propio LLM: De Cero a H√©roe (Gu√≠a Visual)</h1><p>¬†</p><figure class="post__image"><img loading="lazy" src="./media/posts/6/portada.png" alt="" width="2816" height="1536" sizes="(max-width: 48em) 100vw, 768px" srcset="./media/posts/6/responsive/portada-xs.png 300w, ./media/posts/6/responsive/portada-sm.png 480w, ./media/posts/6/responsive/portada-md.png 768w, ./media/posts/6/responsive/portada-lg.png 1024w, ./media/posts/6/responsive/portada-xl.png 1360w, ./media/posts/6/responsive/portada-2xl.png 1600w"></figure><p>¬†</p><p>¬†</p><p>¬°Hola a todos! Hoy os traigo algo especial. Vamos a desmontar la magia de los LLMs. No es tan complicado como parece si tienes paciencia y sigues los pasos.</p><p>He documentado mi viaje creando un modelo desde cero (o casi), y quiero compartir con vosotros cada captura y cada tropiezo (que los hubo). El objetivo es simple: coger un modelo base "tontico" y darle una clase magistral para que se vuelva un experto en nuestro tema.</p><p>¬†</p><div class="tabs"><div class="tab active" style="cursor: default;">Paso 1: El Chiringuito (Entorno)</div></div><div id="mac-content" class="tab-content active"><p>Lo primero es lo primero: el orden. No queremos ensuciar nuestro sistema instalando librer√≠as a lo loco. As√≠ que, carpeta nueva y entorno virtual al canto.</p><div class="code-wrapper"><div class="code-header">1.1 Preparando el terreno</div><pre><code># Creamos la carpeta del proyecto
mkdir mi_propio_llm
cd mi_propio_llm

# Creamos el entorno virtual (VITAL para no romper nada)
python3 -m venv venv

# Lo activamos
source venv/bin/activate</code></pre></div><figure><figure class="post__image"><img loading="lazy" src="file:///h:/2do/IA/crearLm/1.jpeg" alt="Creando el entorno virtual" width="1600" height="900" data-is-external-image="true"></figure></figure><p>Aqu√≠ veis como creo el entorno. Es como crear una caja de arena donde podemos romper cosas sin miedo. Una vez activado (fijaos en el <code>(venv)</code> a la izquierda), estamos listos.</p><p>¬†</p><p>Ahora toca instalar las herramientas. Para Apple Silicon, <code>mlx-lm</code> es mano de santo. Es incre√≠blemente eficiente.</p><div class="code-wrapper"><div class="code-header">1.2 Instalando el motor</div><pre><code># Instalamos las librer√≠as m√°gicas de Apple y HuggingFace
pip install mlx-lm huggingface_hub</code></pre></div><figure><figure class="post__image"><img loading="lazy" src="file:///h:/2do/IA/crearLm/2.jpeg" alt="Instalando dependencias MLX" width="1600" height="900" data-is-external-image="true"></figure></figure><p>Le damos ca√±a al pip install. Aparte de MLX, necesitamos un par de cosillas m√°s para manejar los datos, pero MLX es la estrella aqu√≠.</p><p>¬†</p><p>Siempre me gusta verificar que todo ha ido bien antes de seguir. Un <code>pip list</code> r√°pido nunca est√° de m√°s.</p><figure><figure class="post__image"><img loading="lazy" src="file:///h:/2do/IA/crearLm/3.jpeg" alt="Verificando instalaci√≥n" width="1600" height="900" data-is-external-image="true"></figure></figure><p>Ah√≠ est√° todo. Si veis errores en rojo, parad y arregladlo ahora. Mejor perder 5 minutos aqu√≠ que 5 horas luego.</p><p>¬†</p><div class="code-header">Paso 2: Preparando el "Libro de Texto"</div><p>Un modelo no aprende del aire. Necesitamos datos. Y no cualquier dato, DATOS DE CALIDAD. Aqu√≠ tengo mi archivo original.</p><figure><figure class="post__image"><img loading="lazy" src="file:///h:/2do/IA/crearLm/4.jpeg" alt="Datos en crudo" width="1600" height="900" data-is-external-image="true"></figure></figure><p>Como veis, es texto plano. El modelo no se va a enterar de nada si se lo damos as√≠. Hay que mastic√°rselo.</p><p>¬†</p><p>Aqu√≠ empieza el picar piedra. Limpieza de datos. Quitamos caracteres raros, espacios extra... lo t√≠pico.</p><figure><figure class="post__image"><img loading="lazy" src="file:///h:/2do/IA/crearLm/5.jpeg" alt="Limpieza de datos" width="1600" height="900" data-is-external-image="true"></figure></figure><p>Este paso es aburrido pero CR√çTICO. Si metes basura, sale basura. No hay m√°s.</p><p>¬†</p><p>Ahora viene la conversi√≥n al formato que le gusta a los LLMs: <strong>JSONL</strong>. B√°sicamente es una lista de objetos JSON, uno por l√≠nea.</p><div class="code-wrapper"><div class="code-header">2.1 El formato sagrado (JSONL)</div><pre><code>{"messages": [{"role": "user", "content": "¬øQui√©n eres?"}, {"role": "assistant", "content": "Soy tu IA personalizada."}]}
{"messages": [{"role": "user", "content": "Expl√≠came la relatividad"}, {"role": "assistant", "content": "Todo es relativo, amigo."}]}</code></pre></div><figure><figure class="post__image"><img loading="lazy" src="file:///h:/2do/IA/crearLm/6.jpeg" alt="De texto a JSONL" width="1600" height="900" data-is-external-image="true"></figure></figure><p>Cada l√≠nea tiene una estructura clara: "instrucci√≥n", "entrada" (opcional) y "salida". As√≠ el modelo sabe qu√© le estamos pidiendo y qu√© tiene que responder.</p><p>¬†</p><p>Una √∫ltima revisi√≥n visual al archivo <code>train.jsonl</code>. Tiene buena pinta, ¬øno?</p><figure><figure class="post__image"><img loading="lazy" src="file:///h:/2do/IA/crearLm/7.jpeg" alt="Revisi√≥n final del dataset" width="1600" height="900" data-is-external-image="true"></figure></figure><p>Ya tenemos nuestro libro de texto listo. ¬°A estudiar!</p><p>¬†</p><div class="code-header">Paso 3: El Entrenamiento (Fine-Tuning con LoRA)</div><p>Aqu√≠ es donde la GPU de mi Mac empieza a sudar (bueno, en realidad ni se inmuta, los M1/M2/M3 son unas bestias).</p><div class="code-wrapper"><div class="code-header">3.1 ¬°A entrenar!</div><pre><code># Lanzamos el entrenamiento con LoRA
# Ajusta --iters seg√∫n la cantidad de datos que tengas
python -m mlx_lm.lora \
  --model Qwen/Qwen2.5-0.5B \
  --train \
  --data ./ \
  --iters 600 \
  --batch-size 4 \
  --adapter-path adapters</code></pre></div><figure><figure class="post__image"><img loading="lazy" src="file:///h:/2do/IA/crearLm/8.jpeg" alt="Comando de entrenamiento" width="1600" height="900" data-is-external-image="true"></figure></figure><p>Lanzamos el comando. Usamos <strong>LoRA (Low-Rank Adaptation)</strong>. En cristiano: en vez de reentrenar todo el cerebro del modelo (que es enorme y car√≠simo), le ponemos unas "gafas" finas y solo ajustamos la graduaci√≥n de esas gafas. Es mucho m√°s r√°pido y ocupa poqu√≠simo.</p><p>¬†</p><p>¬°Y arranca! Fijaos en la barra de progreso.</p><figure><figure class="post__image"><img loading="lazy" src="file:///h:/2do/IA/crearLm/9.jpeg" alt="Entrenamiento en marcha" width="1600" height="900" data-is-external-image="true"></figure></figure><p>Lo importante aqu√≠ es la "Loss" (p√©rdida). Queremos que baje. Si sube, malo. Aqu√≠ vemos que va bajando poquito a poco. El modelo est√° "entendiendo".</p><p>¬†</p><p>De vez en cuando echo un ojo a las m√©tricas del sistema.</p><figure><figure class="post__image"><img loading="lazy" src="file:///h:/2do/IA/crearLm/10.jpeg" alt="M√©tricas de sistema" width="1600" height="900" data-is-external-image="true"></figure></figure><p>La memoria unificada est√° trabajando a tope, pero todo estable. Nada de cuelgues.</p><p>¬†</p><figure><figure class="post__image"><img loading="lazy" src="file:///h:/2do/IA/crearLm/11.jpeg" alt="Fin del entrenamiento" width="1600" height="900" data-is-external-image="true"></figure></figure><p>¬°Listo! Ha terminado. Nos ha generado unos archivos peque√±itos (los adaptadores). Eso es lo que contiene el "conocimiento nuevo".</p><p>¬†</p><p>Ahora tenemos el modelo base por un lado y los adaptadores por otro. Hay que fusionarlos.</p><div class="code-wrapper"><div class="code-header">3.2 Fusionando los conocimientos</div><pre><code># Unimos el modelo base con nuestros adaptadores
python -m mlx_lm.fuse \
  --model Qwen/Qwen2.5-0.5B \
  --adapter-path adapters \
  --save-path mi_modelo_final</code></pre></div><figure><figure class="post__image"><img loading="lazy" src="file:///h:/2do/IA/crearLm/12.jpeg" alt="Fusi√≥n de adaptadores" width="1600" height="900" data-is-external-image="true"></figure></figure><p>Con este comando, "pegamos" las gafas al modelo para siempre. Ahora ya es un modelo √∫nico y mejorado.</p><p>¬†</p><div class="code-header">Paso 4: La Hora de la Verdad</div><p>Vale, muy bonito todo, pero ¬øfunciona o solo escupe palabras al azar?</p><div class="code-wrapper"><div class="code-header">4.1 Probando el modelo</div><pre><code># Probamos nuestro modelo reci√©n horneado
python -m mlx_lm.generate \
  --model mi_modelo_final \
  --prompt "Hola, pres√©ntate." \
  --max-tokens 100</code></pre></div><figure><figure class="post__image"><img loading="lazy" src="file:///h:/2do/IA/crearLm/13.jpeg" alt="Primera prueba de inferencia" width="1600" height="900" data-is-external-image="true"></figure></figure><p>Le hago una pregunta del examen. La respuesta es coherente, sigue el formato que le ense√±amos y, lo m√°s importante, ¬°es correcta!</p><p>¬†</p><p>Para que ve√°is la diferencia, mirad esto:</p><figure><figure class="post__image"><img loading="lazy" src="file:///h:/2do/IA/crearLm/14.jpeg" alt="Comparativa base vs finetuned" width="1600" height="900" data-is-external-image="true"></figure></figure><p>A la izquierda, el modelo base divagando. A la derecha, NUESTRO modelo, respondiendo al grano y con estilo. La noche y el d√≠a.</p><p>¬†</p><p>Y hasta aqu√≠ puedo leer. El resto es historia. Si os anim√°is a probarlo, ver√©is que la satisfacci√≥n de que tu propio modelo te responda bien no tiene precio. ¬°Nos vemos en la pr√≥xima!</p></div></div></div></article></main><footer id="copyright"><p>Hecho por Daniel Terroba Alcal√°</p></footer></div><script src="./assets/js/jquery.min.js?v=c9771cc3e90e18f5336eedbd0fffb2cf"></script><script src="./assets/js/jquery.scrollex.min.js?v=f89065e3d988006af9791b44561d7c90"></script><script src="./assets/js/jquery.scrolly.min.js?v=1ed5a78bde1476875a40f6b9ff44fc14"></script><script src="./assets/js/browser.min.js?v=c07298dd19048a8a69ad97e754dfe8d0"></script><script src="./assets/js/breakpoints.min.js?v=81a479eb099e3b187613943b085923b8"></script><script src="./assets/js/util.min.js?v=4201a626f8c9b614a663b3a1d7d82615"></script><script src="./assets/js/main.min.js?v=56233c354bd814758be8bff42f7e13a5"></script><script>/*<![CDATA[*/var images=document.querySelectorAll("img[loading]");for(var i=0;i<images.length;i++){if(images[i].complete){images[i].classList.add("is-loaded")}else{images[i].addEventListener("load",function(){this.classList.add("is-loaded")},false)}};/*]]>*/</script></body></html>